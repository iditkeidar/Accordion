\subsection{Overview}

\begin{figure*}
\caption{\bf{LSM architecture based on compacting memstore.}}
\label{fig:compacting}
\end{figure*}

\sys\/ introduces a {\em compacting\/} memstore to the LSM tree design framework. Contrast to the traditional memstore, 
which maintains all the RAM-resident data in a single monolithic data structure, \sys\/ manages the data as a sequence of 
{\em segments}, ordered by creation time. At all times, the last created segment, called {\em active}, is mutable; it absorbs 
the put operations. The rest of the segments are immutable. The get and scan operations retrieve data from all the segments 
simultaneously, similarly to traditional LSM tree read from multiple levels. Figure~\ref{fig:compacting} illustrates the architecture. 

Once the active segment grows to a $\rho$ fraction of the memstore size bound, an {\em in-memory flush} happens.
The segment becomes immutable. The system queues it up to the list of inactive segments, called {\em pipeline}, 
and creates a new active segment. The  memstore periodically shrinks the pipeline in the background, by applying 
one or more {\em in-memory compaction} mechanisms: 
\begin{enumerate}
\item {\em Flattening of intra-segment search indices.} Since pipelined segments are immutable, it is sufficient to maintain 
their indices as compact ordered arrays, rather than reference-hungry skiplists. An additional advantage of the flat layout 
is that the index can be relocated to off-heap memory (unmanaged by the JVM), which improves performance predictability 
through reduced GC jitter~\cite{alibabahbase}. 
\item {\em Merging multiple segment indices.} A single index covering multiple segment data is created. Redundant data 
versions are not eliminated, to avoid comparisons and physical data copy. 
\item  {\em Merging multiple segment data.} Extends the above with redundant data elimination. The created flat index 
contains no redundancies. In case the memstore manages its cell data storage internally, the surviving cells are relocated
to new slabs; otherwise, the redundant cells are simply de-referenced, and later garbage-collected.    
\end{enumerate} 
The choice of compaction mechanisms is guided by the policies described in Section~\ref{sec:policies}. 

When the region server flushes a compacting memstore to disk, it scans the data from a snapshot 
of the pipelined segments. Similarly to the traditional design, the scan eliminates the redundancies 
prior to flush. 
 
%Summing up, in contrast with traditional memstores that can only grow between disk flushes, compacting memstores 
%can both expand and contract, resembling the movement of accordion bellows. 
%In-memory compactions that reduce the number of immutable segments bound the tail read latencies, as most reads access 
%a few segments. 

\subsection{Compaction Policies}
\label{sec:policies}

We implement three in-memory compaction policies: 
\paragraph{\basic} (low-overhead). Once a segment becomes immutable, flatten its index. Once the pipeline size exceeds $s$, 
merge all segment indices into one.  
\paragraph{\eager} (high-overhead, high-reward under redundancy-heavy workloads). 
In addition to \basic\/ mechanisms, eliminates data redundancies.
\paragraph{\adp} (the best of all worlds). The heuristic adapts to the recent workload, and selects either \basic\/ 
or \eager\/ optimizations depending on the context. \inred{Eshcar, please add the details}. 

\subsection{Implementation Details}

A compacting memstore is comprised from the active segment and a double-ended queue (pipeline) of inactive segments. 
The pipeline is accessed by read API's (get and scan), as well as by backgound disk flushes and in-memory compactions. 
The latter two modify the pipeline, by adding/removing/replacing segments. These modifications happen infrequently. 

The pipeline readers and writers coordinate through a lightweight copy-on-write, as follows. The pipeline object is versioned. 
Each modification promotes the version number, and atomically swaps the global reference to the new version clone. Note
that cloning is inexpensive -- only the segment references are copied since the segments themselves are immutable. 

The reads access the segments lock-free, through the version obtained at the beginning of the operation. If a disk flush
is scheduled in the middle of a read, a segment may migrate from the pipeline to the pre-flush snapshot buffer. The read 
safety is guaranteed by scanning the pipeline clone first. This way, a segment may be encountered twice but no data is 
lost. The scan algorithm filters out the duplicates. 

In-memory compaction is a read-modify-write operation, which swaps one or more segments in the pipeline 
with a new segment built from their data. This operation's atomicity is guaranteed by compare-and-swap (CAS), 
which flips pipeline version only if the latter did not change since the compaction started. Note that it is acceptable
for in-memory compaction to fail sometimes because it is an optimization that may be retried later. 

