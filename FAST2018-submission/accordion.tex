\subsection{Overview}

\begin{figure*}
\caption{\bf{LSM architecture based on compacting memstore.}}
\label{fig:compacting}
\end{figure*}

\sys\/ introduces a {\em compacting\/} memstore to the LSM tree design framework. Contrast to the traditional memstore, 
which maintains all the RAM-resident data in a single monolithic data structure, \sys\/ manages the data as a sequence of 
{\em segments}, ordered by creation time. At all times, the last created segment, called {\em active}, is mutable; it absorbs 
the put operations. The rest of the segments are immutable. The get and scan operations retrieve data from all the segments 
simultaneously, similarly to traditional LSM tree read from multiple levels. Figure~\ref{fig:compacting} illustrates the architecture. 

Once the active segment grows to a $\rho$ fraction of the memstore size bound, an {\em in-memory flush} happens.
The segment becomes immutable. The system queues it up to the list of inactive segments, called {\em pipeline}, 
and creates a new active segment. The  memstore periodically shrinks the pipeline in the background, by applying 
one or more {\em in-memory compaction} mechanisms: 
\begin{enumerate}
\item {\em Flattening of intra-segment search indices.} Since pipelined segments are immutable, it is sufficient to maintain 
their indices as compact ordered arrays, rather than reference-hungry skiplists. An additional advantage of the flat layout 
is that the index can be relocated to off-heap memory (unmanaged by the JVM), which improves performance predictability 
through reduced GC jitter~\cite{?}. 
\item {\em Merging multiple segment indices.} A single index covering multiple segment data is created. Redundant data 
versions are not eliminated, to avoid comparisons and physical data copy. 
\item  {\em Merging multiple segment data.} Extends the above with redundant data elimination. The created flat index 
contains no redundancies. In case the memstore manages its cell data storage internally, the surviving cells are relocated
to new slabs; otherwise, the redundant cells are simply de-referenced, and later garbage-collected.    
\end{enumerate} 
The choice of compaction mechanisms is guided by the policies described in Section~\ref{sec:policies}. 

When the region server flushes a compacting memstore to disk, it scans the data from a snapshot 
of the pipelined segments. Similarly to the traditional design, the scan eliminates the redundancies 
prior to flush. 
 
%Summing up, in contrast with traditional memstores that can only grow between disk flushes, compacting memstores 
%can both expand and contract, resembling the movement of accordion bellows. 
%In-memory compactions that reduce the number of immutable segments bound the tail read latencies, as most reads access 
%a few segments. 

\subsection{Compaction Policies}
\label{sec:policies}

We implement three in-memory compaction policies: 
\paragraph{\basic} (low-overhead). Once a segment becomes immutable, flatten its index. Once the pipeline size exceeds $s$, 
merge all segment indices into one.  
\paragraph{\eager} (high-overhead, high-reward under redundancy-heavy workloads). 
In addition to \basic\/ mechanisms, eliminates data redundancies.
\paragraph{\adp} (the best of all worlds). The heuristic adapts to the recent workload, and selects either \basic\/ 
or \eager\/ optimizations depending on the context. \inred{Eshcar, please add the details}. 

\subsection{Implementation Details}

A compacting memstore is comprised from the active segment and a double-ended queue (pipeline) of inactive segments. 
The pipeline is accessed by read API's (get and scan), as well as by backgound disk flushes and in-memory compactions. 
The latter two modify the pipeline, by adding/removing/replacing segments. These modifications happen infrequently. As 
long as the pipeline does not change, the reads access it via an immutable clone in a lock-free way. Rebuilding the clone
is inexpensive -- it only entails reference copy since the segments themselves are immutable. 

Note that segments might be removed from the pipeline and scheduled for disk flush in parallel with a read from the clone. 
Here, correctness is not affected because the data does not disappear. It might be temporarily referenced from multiple 
locations, though (the pipeline clone and the pre-flush snapshot). The read algorithm filters the duplicates. 

In-memory compaction swaps one or more segments in the queue with new (compacted) segments. It is a long-running operation, 
which should not disrupt the concurrent datapath operations. For that, in-memory compaction works in a non-blocking way. 
The pipeline object maintains a version that is promoted each time the queue tail is modified. When the compaction starts, 
it records this version. Upon completion, it compares the current version with the recorded value, and swaps 
the segments if the latter did not change. The compare-and-swap is atomic (CAS). Since in-memory compaction 
is an optimization, the swap may fail on rare occasions.  

