
We describe  \sys's architecture and basic operation in Section~\ref{ssec:overview}.
We then discuss in-memory compaction policies  in  Section~\ref{ssec:policies}
and implementation details in Section~\ref{ssec:impl-details}. 

\subsection{Overview} \label{ssec:overview}

\begin{figure}[tbh]
\center
\includegraphics[width=\columnwidth]{Accordion} 
\caption{\sys's compacting memory store architecture adds a pipeline of flat segments between the active segment and the snapshot. 
The memory store includes a small dynamic active segment 
and a pipeline of flat segments. A disk flush creates a snapshot of the pipeline for writing to disk.}
\label{fig:accordion}
\end{figure}

\sys\ introduces a \emph{compacting} memory store to the LSM tree design framework. In contrast to the traditional memory store, 
which maintains RAM-resident data in a single monolithic data structure, \sys\ manages data as a \emph{pipeline} of 
\emph{segments} ordered by creation time. At all times, the most recent segment, called \emph{active}, is mutable;
it absorbs  put operations. The rest of the segments are immutable. Get and scan operations retrieve data from all  segments, 
 similarly to a traditional LSM tree read from multiple files. 
 
 Figure~\ref{fig:accordion} illustrates the \sys\ architecture. It is parameterized by two values:
\begin{itemize}
\item  $A$ -- the fraction of the memory store allocated to the active segment; and 
\item $S$ -- the upper bound on the number of immutable segments in the pipeline. 
\end{itemize}

\noindent
As our experiments show (Section~\ref{sec:eval}), the most effective parameter values are quite small, 
e.g., $0.02 \leq A \leq 0.05$, and $1 \leq S \leq 5$.

The memory store dynamics are as follows. 
Once the active segment grows to its size bound (a fraction $A$ of the memory store's size bound), an \emph{in-memory flush} is invoked.
The in-memory flush makes the active segment immutable and creates a new active segment to replace it. 
The replaced active segment is then added to the pipeline in one of three ways. 
\begin{description}
\item[Flattening of intra-segment search indices.] 
In case there is available space in the pipeline (the number of pipeline segments is smaller than $S$), 
the segment is simply flattened. This involves replacing dynamic segment indices such as skiplists by 
compact ordered arrays, which are suitable for immutable data. 
\end{description}
Flattening reduces the MemStore's memory footprint, which delays  disk flushes, positively affecting both read latency  (by increasing the MemStore's hit rate) and write volume.

Once the number of immutable segments exceeds $S$, \emph{in-memory compaction} applies one of the following mechanisms: 
\begin{description}
\item[Merging pipeline segments' search indices.]
 \remove{ % Off-heap stuff omitted due to lack of evaluation
 % To Do: move to conclusions
  An additional advantage of the flat layout  is that in managed environments, 
 the index can be relocated to off-heap (unmanaged) memory, which can improves performance predictability 
 through reduced garbage collection jitter~\cite{alibabahbase}. 
}
This process replaces multiple segments with one by creating a single index covering data that resides 
in the original segments. This is a lightweight process that does not eliminate redundant 
data versions.
%, and hence does not involve physical data copy. 
\item[Merging pipeline segments' data.]
This process extends the above with redundant data elimination -- it 
creates a flat index with no redundancies, and disposes redundant data cells. 
\remove{ % Slab stuff omitted due to lack of evaluation
In case the memstore manages its cell data storage internally, the surviving cells are relocated
to new slabs; otherwise, the redundant cells are simply de-referenced, and later garbage-collected.    
}
\end{description} 
The choice of compaction mechanisms to employ is guided by the policies described in Section~\ref{ssec:policies} below.

Flushes to disk work the same way as in a standard LSM tree. A disk flush shifts all pipeline segments to the snapshot. The pipeline is emptied and ready to absorb new flat segments. The snapshot's immutable flat segments are not part of the pipeline, and are freed once they are written to storage. The background flush process merges the snapshot
segments while eliminating  redundancies, and streams the result to a new file. 

In case the disk flush process empties the pipeline while an in-memory compaction process is attempting to merge some segments, the latter aborts.  This behavior is valid since in-memory compaction is an optimization.

\subsection{Compaction Policies} \label{ssec:policies}

There is a tradeoff between the two in-memory compaction mechanisms. Merging only search indices without removing redundancies is a lighter-weight process.  Moreover, this approach is friendly to the managed memory system because the entire segment is freed at once, whereas 
the data-merging alternative burdens the memory management system (in particular, the garbage collector) by
constantly releasing small objects. On the other hand, the index-merging approach  
consumes memory for overwritten data; this is significant in production-like heavy-tailed distributions where some keys are frequently overwritten.
By removing these redundancies, the data-merging approach further delays disk flushes, which both improves read latency  (thanks to more 
queries being satisfied from memory) and reduces write volume.

Our HBase 2.0 implementation includes two policies corresponding to these two in-memory compaction approaches:
\begin{description}
\item[\basic] (low-overhead). Once a segment becomes immutable, flatten its index. Once the pipeline size exceeds $S$, 
merge all segment indices into one.  
\item[\eager] (high-overhead, high-reward under self-similar workloads). 
Once a segment becomes immutable, merge its index and data with the current (single) pipeline segment.
% In addition to \basic\/ mechanisms, eliminate data redundancies across pipeline segments.
\end{description}

Our experiments (reported in the next section) show that the \eager\ policy is typically too aggressive, in particular when $A$ is small,
and the benefits from reducing the memory footprint are offset by the increased management (and in particular, garbage collection) overhead.
We therefore present in this paper a third policy:
\begin{description}
\item[\adp] (the best of all worlds)\footnote{\small{Not committed to production code yet.}}. A heuristic that chooses 
whether to apply data compaction (as in \eager) or not (as in \basic) based on the level of redundancy in the data 
and the perceived cost-effectiveness of compaction. \adp\ works at the level of a single LSM store, i.e., triggers 
redundancy elimination only for those stores where positive impact is expected. 
\end{description}

\adp\ uses two parameters to determine whether to perform redundancy elimination.
The first is a throttling parameter $t$ based on the amount of data that can benefit from redundancy elimination. 
Initially, $t=0.5$; it then grows exponentially by $2\%$ with the number of in-memory flushes, and is reset back to 
the default value (namely $0.5$) upon disk flush. Thus, $t$ is bigger when there is more data in the MemStore.
The second parameter, $u$, estimates the ratio of unique keys in the memory store based on the 
fraction of unique keys encountered during the previous merge of segment indices. 

Note that the accuracy of $u$ at a given point in time depends on the number of merges that occurred since the last disk flush
or data-merge.
Initially, $u$ is zero, and so the first in-memory compaction does not employ data-merge.
Then, the estimate is based on the $S$ merged components, which at the time for the second in-memory compaction
is roughly one half of the relevant data, since the pipeline holds $S-1$ unmerged components. 
Over time, $u$ becomes more accurate while $t$ grows. 

\adp\/ triggers redundancy elimination with probability $t$ if the fraction of redundant keys $1-u$ exceeds a parameter 
threshold $R$. The rationale for doing so is that prediction based on $u$ becomes more accurate with time, whence 
compactions become more important because the component is bigger and more space can be saved.


\remove{
\begin{description}
\item[\emph{Unique ratio}] $u$ -- an estimate of the fraction of unique keys out of the total number of items in the segment. 
This value is estimated by counting duplicates encountered during merge, which does not induce extra overhead since
merged items are compared in any case. The \emph{unique\_ratio}  is an under-estimate of the actual redundancy because it does not 
take into consideration duplicates that were already present during flattening. Nevertheless, since the active component
is typically quite small, the error due to the under-estimate is significant only when the component is still small 
(has not undergone many merges), and compaction is therefore less important.
\item[\emph{success\_probability}] -- an estimate of the probability of a compaction yielding the expected benefits based on recent history.
Here, we define an expected space reduction threshold below which compaction is not cost-effective. 
We initialize the \emph{success\_probability} to some default value (e.g., $0.5$). 
Then, if compaction yields the expected benefit (i.e., frees up more space than the threshold) we increase the \emph{success\_probability},
and otherwise decrease it. The \emph{success\_probability} is reset to its default value upon flushes. 
The rationale for using \emph{success\_probability} is that its prediction becomes more accurate with time, whence 
compactions become more important because the component is bigger and more space can be saved.
\end{description}
}

\subsection{Concurrency} \label{ssec:impl-details}

A compacting memstore is comprised of an active segment and a double-ended queue (pipeline) of inactive segments. 
The pipeline is accessed by read APIs (get and scan), as well as by background disk flushes and in-memory compactions. 
The latter two modify the pipeline by adding/removing/replacing segments. These modifications happen infrequently. 

The pipeline readers and writers coordinate through a lightweight copy-on-write, as follows. The pipeline object is versioned. 
Each modification promotes the version number, and atomically swaps the global reference to the new version clone. Note
that cloning is inexpensive -- only the segment references are copied since the segments themselves are immutable. 

The reads access the segments lock-free, through the version obtained at the beginning of the operation. If a disk flush
is scheduled in the middle of a read, a segment may migrate from the pipeline to the pre-flush snapshot buffer. The correctness of
reads  is guaranteed by scanning the pipeline clone first. This way, a segment may be encountered twice but no data is 
lost. The scan algorithm filters out the duplicates. 

In-memory compaction is a read-modify-write operation, which swaps one or more segments in the pipeline 
with a new segment built from their data. This operation's atomicity is guaranteed by compare-and-swap (CAS), 
which flips pipeline version only if the latter did not change since the compaction started.  For example, in-memory
compaction fails if a disk flush concurrently removes some segments from the pipeline.
% (Section~\ref{ssec:overview}). 

